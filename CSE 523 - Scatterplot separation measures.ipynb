{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>indexFile</th>\n",
       "      <th>indexDR</th>\n",
       "      <th>classNum</th>\n",
       "      <th>scoreA</th>\n",
       "      <th>scoreM</th>\n",
       "      <th>scoreDes</th>\n",
       "      <th>DSC</th>\n",
       "      <th>CAL</th>\n",
       "      <th>HM</th>\n",
       "      <th>...</th>\n",
       "      <th>DC 20%</th>\n",
       "      <th>HDM 80</th>\n",
       "      <th>DC 2%</th>\n",
       "      <th>DUNN</th>\n",
       "      <th>DC 1%</th>\n",
       "      <th>DC 0.5%</th>\n",
       "      <th>CDM 1</th>\n",
       "      <th>DC 0.2%</th>\n",
       "      <th>DC 0.1%</th>\n",
       "      <th>AWTN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entangled1-3d-3cl-separate_PCA_data.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>83.946488</td>\n",
       "      <td>168.392790</td>\n",
       "      <td>85.211464</td>\n",
       "      <td>...</td>\n",
       "      <td>56.800376</td>\n",
       "      <td>99.775785</td>\n",
       "      <td>93.433032</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>98.920474</td>\n",
       "      <td>99.934515</td>\n",
       "      <td>88.151433</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>330.792098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entangled1-3d-3cl-separate_PCA_data.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>81.438127</td>\n",
       "      <td>202.032855</td>\n",
       "      <td>83.724674</td>\n",
       "      <td>...</td>\n",
       "      <td>54.498185</td>\n",
       "      <td>99.439462</td>\n",
       "      <td>92.019047</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>98.654829</td>\n",
       "      <td>99.904137</td>\n",
       "      <td>81.307295</td>\n",
       "      <td>99.999407</td>\n",
       "      <td>100.0</td>\n",
       "      <td>327.474607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entangled1-3d-3cl-separate_PCA_data.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>83.612040</td>\n",
       "      <td>179.412919</td>\n",
       "      <td>85.662520</td>\n",
       "      <td>...</td>\n",
       "      <td>55.902111</td>\n",
       "      <td>99.663677</td>\n",
       "      <td>93.679104</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>99.009648</td>\n",
       "      <td>99.932368</td>\n",
       "      <td>88.336925</td>\n",
       "      <td>99.999407</td>\n",
       "      <td>100.0</td>\n",
       "      <td>327.621398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entangled1-3d-3cl-separate_RobPCA_data.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>83.919598</td>\n",
       "      <td>181.354553</td>\n",
       "      <td>84.760740</td>\n",
       "      <td>...</td>\n",
       "      <td>57.095953</td>\n",
       "      <td>98.191443</td>\n",
       "      <td>93.611821</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>99.128890</td>\n",
       "      <td>99.879285</td>\n",
       "      <td>82.383557</td>\n",
       "      <td>99.997036</td>\n",
       "      <td>100.0</td>\n",
       "      <td>324.705526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entangled1-3d-3cl-separate_RobPCA_data.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>81.407035</td>\n",
       "      <td>192.947084</td>\n",
       "      <td>83.722177</td>\n",
       "      <td>...</td>\n",
       "      <td>55.212948</td>\n",
       "      <td>98.654709</td>\n",
       "      <td>92.693371</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>99.029505</td>\n",
       "      <td>99.894526</td>\n",
       "      <td>85.241735</td>\n",
       "      <td>99.997332</td>\n",
       "      <td>100.0</td>\n",
       "      <td>324.363518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     fileName  indexFile  indexDR  classNum  \\\n",
       "0     Entangled1-3d-3cl-separate_PCA_data.csv          1        1         1   \n",
       "1     Entangled1-3d-3cl-separate_PCA_data.csv          1        1         2   \n",
       "2     Entangled1-3d-3cl-separate_PCA_data.csv          1        1         3   \n",
       "3  Entangled1-3d-3cl-separate_RobPCA_data.csv          1        2         1   \n",
       "4  Entangled1-3d-3cl-separate_RobPCA_data.csv          1        2         2   \n",
       "\n",
       "   scoreA  scoreM  scoreDes        DSC         CAL         HM     ...      \\\n",
       "0       5       4         1  83.946488  168.392790  85.211464     ...       \n",
       "1       5       4         1  81.438127  202.032855  83.724674     ...       \n",
       "2       5       4         1  83.612040  179.412919  85.662520     ...       \n",
       "3       5       4         1  83.919598  181.354553  84.760740     ...       \n",
       "4       5       4         1  81.407035  192.947084  83.722177     ...       \n",
       "\n",
       "      DC 20%     HDM 80      DC 2%      DUNN      DC 1%    DC 0.5%      CDM 1  \\\n",
       "0  56.800376  99.775785  93.433032  0.003952  98.920474  99.934515  88.151433   \n",
       "1  54.498185  99.439462  92.019047  0.003344  98.654829  99.904137  81.307295   \n",
       "2  55.902111  99.663677  93.679104  0.003371  99.009648  99.932368  88.336925   \n",
       "3  57.095953  98.191443  93.611821  0.002583  99.128890  99.879285  82.383557   \n",
       "4  55.212948  98.654709  92.693371  0.002513  99.029505  99.894526  85.241735   \n",
       "\n",
       "      DC 0.2%  DC 0.1%        AWTN  \n",
       "0  100.000000    100.0  330.792098  \n",
       "1   99.999407    100.0  327.474607  \n",
       "2   99.999407    100.0  327.621398  \n",
       "3   99.997036    100.0  324.705526  \n",
       "4   99.997332    100.0  324.363518  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"RESULTS_EUROVIS2015.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSC</th>\n",
       "      <th>CAL</th>\n",
       "      <th>HM</th>\n",
       "      <th>LDA</th>\n",
       "      <th>WII</th>\n",
       "      <th>SIL</th>\n",
       "      <th>GAM</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CS</th>\n",
       "      <th>HDM 10</th>\n",
       "      <th>...</th>\n",
       "      <th>DC 20%</th>\n",
       "      <th>HDM 80</th>\n",
       "      <th>DC 2%</th>\n",
       "      <th>DUNN</th>\n",
       "      <th>DC 1%</th>\n",
       "      <th>DC 0.5%</th>\n",
       "      <th>CDM 1</th>\n",
       "      <th>DC 0.2%</th>\n",
       "      <th>DC 0.1%</th>\n",
       "      <th>AWTN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.946488</td>\n",
       "      <td>168.392790</td>\n",
       "      <td>85.211464</td>\n",
       "      <td>0.233286</td>\n",
       "      <td>0.320842</td>\n",
       "      <td>0.244208</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>1.307991</td>\n",
       "      <td>0.910946</td>\n",
       "      <td>79.906761</td>\n",
       "      <td>...</td>\n",
       "      <td>56.800376</td>\n",
       "      <td>99.775785</td>\n",
       "      <td>93.433032</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>98.920474</td>\n",
       "      <td>99.934515</td>\n",
       "      <td>88.151433</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>330.792098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.438127</td>\n",
       "      <td>202.032855</td>\n",
       "      <td>83.724674</td>\n",
       "      <td>0.574045</td>\n",
       "      <td>0.305026</td>\n",
       "      <td>0.249141</td>\n",
       "      <td>0.339768</td>\n",
       "      <td>1.333924</td>\n",
       "      <td>0.774196</td>\n",
       "      <td>75.904697</td>\n",
       "      <td>...</td>\n",
       "      <td>54.498185</td>\n",
       "      <td>99.439462</td>\n",
       "      <td>92.019047</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>98.654829</td>\n",
       "      <td>99.904137</td>\n",
       "      <td>81.307295</td>\n",
       "      <td>99.999407</td>\n",
       "      <td>100.0</td>\n",
       "      <td>327.474607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.612040</td>\n",
       "      <td>179.412919</td>\n",
       "      <td>85.662520</td>\n",
       "      <td>0.915691</td>\n",
       "      <td>0.313059</td>\n",
       "      <td>0.249217</td>\n",
       "      <td>0.339577</td>\n",
       "      <td>1.331933</td>\n",
       "      <td>0.904530</td>\n",
       "      <td>81.196308</td>\n",
       "      <td>...</td>\n",
       "      <td>55.902111</td>\n",
       "      <td>99.663677</td>\n",
       "      <td>93.679104</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>99.009648</td>\n",
       "      <td>99.932368</td>\n",
       "      <td>88.336925</td>\n",
       "      <td>99.999407</td>\n",
       "      <td>100.0</td>\n",
       "      <td>327.621398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.919598</td>\n",
       "      <td>181.354553</td>\n",
       "      <td>84.760740</td>\n",
       "      <td>0.095612</td>\n",
       "      <td>0.312085</td>\n",
       "      <td>0.250118</td>\n",
       "      <td>0.334770</td>\n",
       "      <td>1.324574</td>\n",
       "      <td>0.801723</td>\n",
       "      <td>77.244476</td>\n",
       "      <td>...</td>\n",
       "      <td>57.095953</td>\n",
       "      <td>98.191443</td>\n",
       "      <td>93.611821</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>99.128890</td>\n",
       "      <td>99.879285</td>\n",
       "      <td>82.383557</td>\n",
       "      <td>99.997036</td>\n",
       "      <td>100.0</td>\n",
       "      <td>324.705526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.407035</td>\n",
       "      <td>192.947084</td>\n",
       "      <td>83.722177</td>\n",
       "      <td>0.704854</td>\n",
       "      <td>0.309980</td>\n",
       "      <td>0.246604</td>\n",
       "      <td>0.332735</td>\n",
       "      <td>1.324828</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>75.415086</td>\n",
       "      <td>...</td>\n",
       "      <td>55.212948</td>\n",
       "      <td>98.654709</td>\n",
       "      <td>92.693371</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>99.029505</td>\n",
       "      <td>99.894526</td>\n",
       "      <td>85.241735</td>\n",
       "      <td>99.997332</td>\n",
       "      <td>100.0</td>\n",
       "      <td>324.363518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DSC         CAL         HM       LDA       WII       SIL       GAM  \\\n",
       "0  83.946488  168.392790  85.211464  0.233286  0.320842  0.244208  0.320500   \n",
       "1  81.438127  202.032855  83.724674  0.574045  0.305026  0.249141  0.339768   \n",
       "2  83.612040  179.412919  85.662520  0.915691  0.313059  0.249217  0.339577   \n",
       "3  83.919598  181.354553  84.760740  0.095612  0.312085  0.250118  0.334770   \n",
       "4  81.407035  192.947084  83.722177  0.704854  0.309980  0.246604  0.332735   \n",
       "\n",
       "        ABW        CS     HDM 10     ...         DC 20%     HDM 80      DC 2%  \\\n",
       "0  1.307991  0.910946  79.906761     ...      56.800376  99.775785  93.433032   \n",
       "1  1.333924  0.774196  75.904697     ...      54.498185  99.439462  92.019047   \n",
       "2  1.331933  0.904530  81.196308     ...      55.902111  99.663677  93.679104   \n",
       "3  1.324574  0.801723  77.244476     ...      57.095953  98.191443  93.611821   \n",
       "4  1.324828  0.890831  75.415086     ...      55.212948  98.654709  92.693371   \n",
       "\n",
       "       DUNN      DC 1%    DC 0.5%      CDM 1     DC 0.2%  DC 0.1%        AWTN  \n",
       "0  0.003952  98.920474  99.934515  88.151433  100.000000    100.0  330.792098  \n",
       "1  0.003344  98.654829  99.904137  81.307295   99.999407    100.0  327.474607  \n",
       "2  0.003371  99.009648  99.932368  88.336925   99.999407    100.0  327.621398  \n",
       "3  0.002583  99.128890  99.879285  82.383557   99.997036    100.0  324.705526  \n",
       "4  0.002513  99.029505  99.894526  85.241735   99.997332    100.0  324.363518  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:-1]\n",
    "\n",
    "metrics_data = data.iloc[:,7:42]\n",
    "metrics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 35)\n",
      "(166, 35)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X = train_test_split(metrics_data, test_size=0.2)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662,)\n",
      "(166,)\n"
     ]
    }
   ],
   "source": [
    "labels = data['scoreDes']\n",
    "train_y, test_y = train_test_split(labels, test_size=0.2)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4759036144578313"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression().fit(train_X, train_y)\n",
    "reg_predictions = reg.predict(test_X)\n",
    "accuracy_score(reg_predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(units=35, activation='relu', input_shape=(35,)))\n",
    "network.add(Dense(units=35, activation='relu'))\n",
    "network.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss='binary_crossentropy', \n",
    "                optimizer='rmsprop', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "662/662 [==============================] - 0s 153us/step - loss: 6.4345 - acc: 0.5076\n",
      "Epoch 2/100\n",
      "662/662 [==============================] - 0s 22us/step - loss: 5.1237 - acc: 0.4834\n",
      "Epoch 3/100\n",
      "662/662 [==============================] - 0s 23us/step - loss: 4.2611 - acc: 0.5045\n",
      "Epoch 4/100\n",
      "662/662 [==============================] - 0s 50us/step - loss: 3.6407 - acc: 0.4985\n",
      "Epoch 5/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 3.6790 - acc: 0.4894\n",
      "Epoch 6/100\n",
      "662/662 [==============================] - 0s 49us/step - loss: 3.5060 - acc: 0.4970\n",
      "Epoch 7/100\n",
      "662/662 [==============================] - 0s 47us/step - loss: 2.8360 - acc: 0.5015\n",
      "Epoch 8/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 2.9019 - acc: 0.4985\n",
      "Epoch 9/100\n",
      "662/662 [==============================] - 0s 28us/step - loss: 2.2654 - acc: 0.5332\n",
      "Epoch 10/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 2.1443 - acc: 0.5196\n",
      "Epoch 11/100\n",
      "662/662 [==============================] - 0s 54us/step - loss: 2.3738 - acc: 0.5106\n",
      "Epoch 12/100\n",
      "662/662 [==============================] - 0s 51us/step - loss: 2.3240 - acc: 0.5030\n",
      "Epoch 13/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 2.1833 - acc: 0.5317\n",
      "Epoch 14/100\n",
      "662/662 [==============================] - 0s 48us/step - loss: 2.7156 - acc: 0.4864\n",
      "Epoch 15/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.9254 - acc: 0.5227\n",
      "Epoch 16/100\n",
      "662/662 [==============================] - 0s 30us/step - loss: 2.5224 - acc: 0.5151\n",
      "Epoch 17/100\n",
      "662/662 [==============================] - 0s 28us/step - loss: 2.1711 - acc: 0.5121\n",
      "Epoch 18/100\n",
      "662/662 [==============================] - 0s 47us/step - loss: 1.9335 - acc: 0.5166\n",
      "Epoch 19/100\n",
      "662/662 [==============================] - 0s 63us/step - loss: 2.0182 - acc: 0.5211\n",
      "Epoch 20/100\n",
      "662/662 [==============================] - 0s 31us/step - loss: 2.0507 - acc: 0.5302\n",
      "Epoch 21/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.6219 - acc: 0.5408\n",
      "Epoch 22/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 2.3983 - acc: 0.4985\n",
      "Epoch 23/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.9769 - acc: 0.5151\n",
      "Epoch 24/100\n",
      "662/662 [==============================] - 0s 46us/step - loss: 1.7792 - acc: 0.5015\n",
      "Epoch 25/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 2.1186 - acc: 0.4940\n",
      "Epoch 26/100\n",
      "662/662 [==============================] - ETA: 0s - loss: 1.9423 - acc: 0.590 - 0s 41us/step - loss: 1.4545 - acc: 0.5634\n",
      "Epoch 27/100\n",
      "662/662 [==============================] - 0s 51us/step - loss: 1.8419 - acc: 0.5363\n",
      "Epoch 28/100\n",
      "662/662 [==============================] - 0s 62us/step - loss: 1.6990 - acc: 0.5211\n",
      "Epoch 29/100\n",
      "662/662 [==============================] - 0s 51us/step - loss: 1.6978 - acc: 0.5483\n",
      "Epoch 30/100\n",
      "662/662 [==============================] - 0s 25us/step - loss: 2.1748 - acc: 0.4879\n",
      "Epoch 31/100\n",
      "662/662 [==============================] - 0s 53us/step - loss: 1.9483 - acc: 0.4909\n",
      "Epoch 32/100\n",
      "662/662 [==============================] - 0s 48us/step - loss: 1.6620 - acc: 0.5287\n",
      "Epoch 33/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.5789 - acc: 0.5332\n",
      "Epoch 34/100\n",
      "662/662 [==============================] - 0s 26us/step - loss: 1.7340 - acc: 0.5196\n",
      "Epoch 35/100\n",
      "662/662 [==============================] - 0s 37us/step - loss: 1.7348 - acc: 0.5257\n",
      "Epoch 36/100\n",
      "662/662 [==============================] - 0s 43us/step - loss: 1.6051 - acc: 0.5408\n",
      "Epoch 37/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.3565 - acc: 0.5665\n",
      "Epoch 38/100\n",
      "662/662 [==============================] - 0s 24us/step - loss: 1.9300 - acc: 0.5151\n",
      "Epoch 39/100\n",
      "662/662 [==============================] - 0s 44us/step - loss: 1.4584 - acc: 0.5378\n",
      "Epoch 40/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.5594 - acc: 0.5302\n",
      "Epoch 41/100\n",
      "662/662 [==============================] - 0s 45us/step - loss: 1.6025 - acc: 0.5136\n",
      "Epoch 42/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.7645 - acc: 0.4849\n",
      "Epoch 43/100\n",
      "662/662 [==============================] - 0s 30us/step - loss: 1.3281 - acc: 0.5468\n",
      "Epoch 44/100\n",
      "662/662 [==============================] - 0s 22us/step - loss: 1.4623 - acc: 0.5453\n",
      "Epoch 45/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 1.2818 - acc: 0.5529\n",
      "Epoch 46/100\n",
      "662/662 [==============================] - 0s 39us/step - loss: 1.4270 - acc: 0.5438\n",
      "Epoch 47/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.7192 - acc: 0.4849\n",
      "Epoch 48/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 0.9629 - acc: 0.5634\n",
      "Epoch 49/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 1.7470 - acc: 0.5091\n",
      "Epoch 50/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 1.5107 - acc: 0.5196\n",
      "Epoch 51/100\n",
      "662/662 [==============================] - 0s 52us/step - loss: 1.4943 - acc: 0.5121\n",
      "Epoch 52/100\n",
      "662/662 [==============================] - 0s 50us/step - loss: 1.1357 - acc: 0.5227\n",
      "Epoch 53/100\n",
      "662/662 [==============================] - 0s 41us/step - loss: 1.4073 - acc: 0.5287\n",
      "Epoch 54/100\n",
      "662/662 [==============================] - 0s 25us/step - loss: 1.1833 - acc: 0.5438\n",
      "Epoch 55/100\n",
      "662/662 [==============================] - 0s 28us/step - loss: 1.3543 - acc: 0.5529\n",
      "Epoch 56/100\n",
      "662/662 [==============================] - 0s 34us/step - loss: 1.4369 - acc: 0.5045\n",
      "Epoch 57/100\n",
      "662/662 [==============================] - 0s 31us/step - loss: 1.1836 - acc: 0.5589\n",
      "Epoch 58/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.3741 - acc: 0.5060\n",
      "Epoch 59/100\n",
      "662/662 [==============================] - 0s 27us/step - loss: 1.1312 - acc: 0.5483\n",
      "Epoch 60/100\n",
      "662/662 [==============================] - 0s 40us/step - loss: 1.1625 - acc: 0.5347\n",
      "Epoch 61/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 1.4053 - acc: 0.5121\n",
      "Epoch 62/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.1672 - acc: 0.5589\n",
      "Epoch 63/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 1.2613 - acc: 0.5302\n",
      "Epoch 64/100\n",
      "662/662 [==============================] - 0s 24us/step - loss: 1.3125 - acc: 0.5438\n",
      "Epoch 65/100\n",
      "662/662 [==============================] - 0s 34us/step - loss: 1.3532 - acc: 0.4924\n",
      "Epoch 66/100\n",
      "662/662 [==============================] - 0s 31us/step - loss: 1.0893 - acc: 0.5211\n",
      "Epoch 67/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 1.2794 - acc: 0.5151\n",
      "Epoch 68/100\n",
      "662/662 [==============================] - 0s 26us/step - loss: 1.0455 - acc: 0.5589\n",
      "Epoch 69/100\n",
      "662/662 [==============================] - 0s 23us/step - loss: 1.2946 - acc: 0.5211\n",
      "Epoch 70/100\n",
      "662/662 [==============================] - 0s 25us/step - loss: 0.8504 - acc: 0.6027\n",
      "Epoch 71/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 1.2767 - acc: 0.5453\n",
      "Epoch 72/100\n",
      "662/662 [==============================] - 0s 30us/step - loss: 1.1420 - acc: 0.5317\n",
      "Epoch 73/100\n",
      "662/662 [==============================] - 0s 30us/step - loss: 1.1205 - acc: 0.5438\n",
      "Epoch 74/100\n",
      "662/662 [==============================] - 0s 37us/step - loss: 1.0822 - acc: 0.5423\n",
      "Epoch 75/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 1.0377 - acc: 0.5665\n",
      "Epoch 76/100\n",
      "662/662 [==============================] - 0s 27us/step - loss: 1.2643 - acc: 0.5363\n",
      "Epoch 77/100\n",
      "662/662 [==============================] - 0s 23us/step - loss: 1.1711 - acc: 0.5287\n",
      "Epoch 78/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.1058 - acc: 0.5151\n",
      "Epoch 79/100\n",
      "662/662 [==============================] - 0s 31us/step - loss: 1.0166 - acc: 0.5498\n",
      "Epoch 80/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 1.2396 - acc: 0.5211\n",
      "Epoch 81/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.0669 - acc: 0.5468\n",
      "Epoch 82/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 0.9418 - acc: 0.5544\n",
      "Epoch 83/100\n",
      "662/662 [==============================] - 0s 23us/step - loss: 1.0862 - acc: 0.5544\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/662 [==============================] - 0s 41us/step - loss: 1.0162 - acc: 0.5468\n",
      "Epoch 85/100\n",
      "662/662 [==============================] - 0s 39us/step - loss: 1.2840 - acc: 0.5030\n",
      "Epoch 86/100\n",
      "662/662 [==============================] - 0s 28us/step - loss: 1.1532 - acc: 0.4909\n",
      "Epoch 87/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 0.8370 - acc: 0.5650\n",
      "Epoch 88/100\n",
      "662/662 [==============================] - 0s 28us/step - loss: 1.0356 - acc: 0.5589\n",
      "Epoch 89/100\n",
      "662/662 [==============================] - 0s 36us/step - loss: 1.1109 - acc: 0.5211\n",
      "Epoch 90/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 0.8597 - acc: 0.5529\n",
      "Epoch 91/100\n",
      "662/662 [==============================] - 0s 30us/step - loss: 1.0458 - acc: 0.5634\n",
      "Epoch 92/100\n",
      "662/662 [==============================] - 0s 27us/step - loss: 0.9608 - acc: 0.5755\n",
      "Epoch 93/100\n",
      "662/662 [==============================] - 0s 46us/step - loss: 1.1447 - acc: 0.5272\n",
      "Epoch 94/100\n",
      "662/662 [==============================] - 0s 26us/step - loss: 0.9425 - acc: 0.5589\n",
      "Epoch 95/100\n",
      "662/662 [==============================] - 0s 29us/step - loss: 1.0271 - acc: 0.5514\n",
      "Epoch 96/100\n",
      "662/662 [==============================] - 0s 33us/step - loss: 0.8346 - acc: 0.5710\n",
      "Epoch 97/100\n",
      "662/662 [==============================] - 0s 27us/step - loss: 1.0956 - acc: 0.5544\n",
      "Epoch 98/100\n",
      "662/662 [==============================] - 0s 27us/step - loss: 1.0720 - acc: 0.5378\n",
      "Epoch 99/100\n",
      "662/662 [==============================] - 0s 32us/step - loss: 0.9905 - acc: 0.5574\n",
      "Epoch 100/100\n",
      "662/662 [==============================] - 0s 35us/step - loss: 0.9929 - acc: 0.5468\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(train_X,\n",
    "                      train_y,\n",
    "                      epochs=100,\n",
    "                      verbose=1,\n",
    "                      batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4759036144578313"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_predictions = network.predict(test_X)\n",
    "nn_predictions = (nn_predictions > 0.5)\n",
    "accuracy_score(nn_predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5060240963855421"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR(gamma=0.001, C=1.0, epsilon=0.2)\n",
    "svr.fit(train_X, train_y)\n",
    "svr_predictions = svr.predict(test_X)\n",
    "svr_predictions = (svr_predictions > 0.5)\n",
    "accuracy_score(svr_predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
